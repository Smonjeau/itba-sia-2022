from enum import auto
import numpy as np
import matplotlib.pyplot as plt
from algorithm import Autoencoder
def to_bin_array(encoded_caracter):
    bin_array = np.zeros((7, 5), dtype=int)
    for row in range(0, 7):
        current_row = encoded_caracter[row]
        for col in range(0, 5):
            bin_array[row][4-col] = current_row & 1
            current_row >>= 1
    return bin_array.flatten()

font_3 = np.array([
   [0x04, 0x04, 0x02, 0x00, 0x00, 0x00, 0x00],   # 0x60, `
   [0x00, 0x0e, 0x01, 0x0d, 0x13, 0x13, 0x0d],   # 0x61, a
   [0x10, 0x10, 0x10, 0x1c, 0x12, 0x12, 0x1c],   # 0x62, b
   [0x00, 0x00, 0x00, 0x0e, 0x10, 0x10, 0x0e],   # 0x63, c
   [0x01, 0x01, 0x01, 0x07, 0x09, 0x09, 0x07],   # 0x64, d
   [0x00, 0x00, 0x0e, 0x11, 0x1f, 0x10, 0x0f],   # 0x65, e
   [0x06, 0x09, 0x08, 0x1c, 0x08, 0x08, 0x08],   # 0x66, f
   [0x0e, 0x11, 0x13, 0x0d, 0x01, 0x01, 0x0e],   # 0x67, g
   [0x10, 0x10, 0x10, 0x16, 0x19, 0x11, 0x11],   # 0x68, h
   [0x00, 0x04, 0x00, 0x0c, 0x04, 0x04, 0x0e],   # 0x69, i
   [0x02, 0x00, 0x06, 0x02, 0x02, 0x12, 0x0c],   # 0x6a, j
   [0x10, 0x10, 0x12, 0x14, 0x18, 0x14, 0x12],   # 0x6b, k
   [0x0c, 0x04, 0x04, 0x04, 0x04, 0x04, 0x04],   # 0x6c, l
   [0x00, 0x00, 0x0a, 0x15, 0x15, 0x11, 0x11],   # 0x6d, m
   [0x00, 0x00, 0x16, 0x19, 0x11, 0x11, 0x11],   # 0x6e, n
   [0x00, 0x00, 0x0e, 0x11, 0x11, 0x11, 0x0e],   # 0x6f, o
   [0x00, 0x1c, 0x12, 0x12, 0x1c, 0x10, 0x10],   # 0x70, p
   [0x00, 0x07, 0x09, 0x09, 0x07, 0x01, 0x01],   # 0x71, q
   [0x00, 0x00, 0x16, 0x19, 0x10, 0x10, 0x10],   # 0x72, r
   [0x00, 0x00, 0x0f, 0x10, 0x0e, 0x01, 0x1e],   # 0x73, s
   [0x08, 0x08, 0x1c, 0x08, 0x08, 0x09, 0x06],   # 0x74, t
   [0x00, 0x00, 0x11, 0x11, 0x11, 0x13, 0x0d],   # 0x75, u
   [0x00, 0x00, 0x11, 0x11, 0x11, 0x0a, 0x04],   # 0x76, v
   [0x00, 0x00, 0x11, 0x11, 0x15, 0x15, 0x0a],   # 0x77, w
   [0x00, 0x00, 0x11, 0x0a, 0x04, 0x0a, 0x11],   # 0x78, x
   [0x00, 0x11, 0x11, 0x0f, 0x01, 0x11, 0x0e],   # 0x79, y
   [0x00, 0x00, 0x1f, 0x02, 0x04, 0x08, 0x1f],   # 0x7a, z
   [0x06, 0x08, 0x08, 0x10, 0x08, 0x08, 0x06],   # 0x7b, [
   [0x04, 0x04, 0x04, 0x00, 0x04, 0x04, 0x04],   # 0x7c, |
   [0x0c, 0x02, 0x02, 0x01, 0x02, 0x02, 0x0c],   # 0x7d, ]
   [0x08, 0x15, 0x02, 0x00, 0x00, 0x00, 0x00],   # 0x7e, ~
   [0x1f, 0x1f, 0x1f, 0x1f, 0x1f, 0x1f, 0x1f]   # 0x7f, DEL
   ])

neurons_per_layer = [20, 10, 2,10,20]


font_keys = ["`", "a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m", "n", "o", "p", "q", "r", "s", "t", "u", "v", "w", "x", "y", "z", "[", "|","]", "~", "DEL"]
font_dict ={}
for i in range(len(font_keys)):
    font_dict[font_keys[i]] = to_bin_array(font_3[i])

#print(font_dict)

pat1 = ('`', 'a', 'b', 'c', 'd', 'e', 'f', 'x', '|', '~') #2.62
pat2 = ('`', 'a', 'b', 'c', 'd', 'e', 'f', '|', ']', '~') #2.8
pat3 = ('`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'r', '~') # 3.56
pat4 = ('`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'r', 'z') # 4.18
pat5 = ('`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'r', 'y') #4.58
pat6 = ('`', 'a', 'b', 'c', 'd', 'e', 'f', 'p', '[', 'DEL') #5.16
pat7 = ('`', 'a', 'b', 'c', 'd', 'e', 'f', 'p', 'y', 'DEL') #5.71
pat8 = ('`', 'a', 'b', 'c', 'd', 'e', 'k', 'o', 'y', 'DEL') #6.22
pat9 = ('`', 'a', 'b', 'c', 'd', 'e', 'g', 'y', 'z', 'DEL') #6.56

avg_dot_prod = [2.62, 2.8, 3.56, 4.18, 4.58, 5.16, 5.71, 6.22, 6.56]
pats = [pat1,pat2, pat3,pat4, pat5, pat6, pat7, pat8, pat9]

errors = []
for pat in pats:
    subset = []
    for key in pat:
        subset.append(font_dict[key])

    autoencoder = Autoencoder(neurons_per_layer, subset, subset, 1)
    print("Training...")
    autoencoder.train()
    errors.append(autoencoder.errors_per_step[-1])

print(errors)

plt.plot(avg_dot_prod, errors)
plt.xlabel("Producto interno entre letras")
plt.ylabel("Error Promedio") 
plt.show()